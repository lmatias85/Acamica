{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian', \n",
    "              'comp.graphics', 'sci.med']\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', \n",
    "                                  categories=categories, \n",
    "                                  shuffle=True, random_state=42)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "                                 categories=categories, \n",
    "                                 shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "X_train = tf_idf.fit_transform(twenty_train.data)\n",
    "X_test = tf_idf.transform(twenty_test.data)\n",
    "y_train = twenty_train.target\n",
    "y_test = twenty_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
       "      n_jobs=None, penalty=None, random_state=0, shuffle=True, tol=None,\n",
       "      validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron()\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9141145139813582"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(10,), random_state=42)\n",
    "mlp_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9300932090545939"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mlp_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#pip install --upgrade numpy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dicsys\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                572624    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 572,964\n",
      "Trainable params: 572,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(max_features,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dicsys\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1805 samples, validate on 452 samples\n",
      "Epoch 1/50\n",
      "1805/1805 [==============================] - 2s 921us/step - loss: 1.3688 - acc: 0.5773 - val_loss: 1.3336 - val_acc: 0.7168\n",
      "Epoch 2/50\n",
      "1805/1805 [==============================] - 1s 660us/step - loss: 1.2995 - acc: 0.7878 - val_loss: 1.2855 - val_acc: 0.7323\n",
      "Epoch 3/50\n",
      "1805/1805 [==============================] - 1s 700us/step - loss: 1.2381 - acc: 0.7928 - val_loss: 1.2423 - val_acc: 0.7301\n",
      "Epoch 4/50\n",
      "1805/1805 [==============================] - 1s 680us/step - loss: 1.1805 - acc: 0.8061 - val_loss: 1.1998 - val_acc: 0.7412\n",
      "Epoch 5/50\n",
      "1805/1805 [==============================] - 1s 682us/step - loss: 1.1246 - acc: 0.8294 - val_loss: 1.1590 - val_acc: 0.7434\n",
      "Epoch 6/50\n",
      "1805/1805 [==============================] - 1s 609us/step - loss: 1.0698 - acc: 0.8338 - val_loss: 1.1170 - val_acc: 0.7765\n",
      "Epoch 7/50\n",
      "1805/1805 [==============================] - 1s 689us/step - loss: 1.0150 - acc: 0.8576 - val_loss: 1.0757 - val_acc: 0.7810\n",
      "Epoch 8/50\n",
      "1805/1805 [==============================] - 1s 696us/step - loss: 0.9611 - acc: 0.8737 - val_loss: 1.0341 - val_acc: 0.7965\n",
      "Epoch 9/50\n",
      "1805/1805 [==============================] - 1s 687us/step - loss: 0.9074 - acc: 0.8964 - val_loss: 0.9914 - val_acc: 0.8119\n",
      "Epoch 10/50\n",
      "1805/1805 [==============================] - 1s 680us/step - loss: 0.8521 - acc: 0.9247 - val_loss: 0.9457 - val_acc: 0.8296\n",
      "Epoch 11/50\n",
      "1805/1805 [==============================] - 1s 683us/step - loss: 0.7962 - acc: 0.9385 - val_loss: 0.9047 - val_acc: 0.8385\n",
      "Epoch 12/50\n",
      "1805/1805 [==============================] - 1s 666us/step - loss: 0.7427 - acc: 0.9479 - val_loss: 0.8620 - val_acc: 0.8650\n",
      "Epoch 13/50\n",
      "1805/1805 [==============================] - 1s 652us/step - loss: 0.6920 - acc: 0.9618 - val_loss: 0.8224 - val_acc: 0.8717\n",
      "Epoch 14/50\n",
      "1805/1805 [==============================] - 1s 685us/step - loss: 0.6429 - acc: 0.9695 - val_loss: 0.7838 - val_acc: 0.8739\n",
      "Epoch 15/50\n",
      "1805/1805 [==============================] - 1s 677us/step - loss: 0.5960 - acc: 0.9795 - val_loss: 0.7439 - val_acc: 0.8761\n",
      "Epoch 16/50\n",
      "1805/1805 [==============================] - 1s 698us/step - loss: 0.5512 - acc: 0.9845 - val_loss: 0.7070 - val_acc: 0.8872\n",
      "Epoch 17/50\n",
      "1805/1805 [==============================] - 1s 690us/step - loss: 0.5089 - acc: 0.9878 - val_loss: 0.6722 - val_acc: 0.8938\n",
      "Epoch 18/50\n",
      "1805/1805 [==============================] - 1s 668us/step - loss: 0.4680 - acc: 0.9934 - val_loss: 0.6386 - val_acc: 0.8960\n",
      "Epoch 19/50\n",
      "1805/1805 [==============================] - 1s 676us/step - loss: 0.4296 - acc: 0.9939 - val_loss: 0.6044 - val_acc: 0.9159\n",
      "Epoch 20/50\n",
      "1805/1805 [==============================] - 1s 672us/step - loss: 0.3929 - acc: 0.9950 - val_loss: 0.5707 - val_acc: 0.9159\n",
      "Epoch 21/50\n",
      "1805/1805 [==============================] - 1s 685us/step - loss: 0.3585 - acc: 0.9972 - val_loss: 0.5404 - val_acc: 0.9204\n",
      "Epoch 22/50\n",
      "1805/1805 [==============================] - 1s 655us/step - loss: 0.3263 - acc: 0.9983 - val_loss: 0.5116 - val_acc: 0.9181\n",
      "Epoch 23/50\n",
      "1805/1805 [==============================] - 1s 680us/step - loss: 0.2959 - acc: 0.9989 - val_loss: 0.4815 - val_acc: 0.9226\n",
      "Epoch 24/50\n",
      "1805/1805 [==============================] - 1s 689us/step - loss: 0.2678 - acc: 0.9994 - val_loss: 0.4565 - val_acc: 0.9270\n",
      "Epoch 25/50\n",
      "1805/1805 [==============================] - 1s 681us/step - loss: 0.2418 - acc: 0.9994 - val_loss: 0.4301 - val_acc: 0.9403\n",
      "Epoch 26/50\n",
      "1805/1805 [==============================] - 1s 688us/step - loss: 0.2176 - acc: 0.9994 - val_loss: 0.4059 - val_acc: 0.9403\n",
      "Epoch 27/50\n",
      "1805/1805 [==============================] - 1s 677us/step - loss: 0.1953 - acc: 0.9994 - val_loss: 0.3808 - val_acc: 0.9447\n",
      "Epoch 28/50\n",
      "1805/1805 [==============================] - 1s 675us/step - loss: 0.1750 - acc: 0.9994 - val_loss: 0.3615 - val_acc: 0.9469\n",
      "Epoch 29/50\n",
      "1805/1805 [==============================] - 1s 678us/step - loss: 0.1566 - acc: 0.9994 - val_loss: 0.3402 - val_acc: 0.9513\n",
      "Epoch 30/50\n",
      "1805/1805 [==============================] - 1s 670us/step - loss: 0.1398 - acc: 0.9994 - val_loss: 0.3229 - val_acc: 0.9513\n",
      "Epoch 31/50\n",
      "1805/1805 [==============================] - 1s 709us/step - loss: 0.1247 - acc: 0.9994 - val_loss: 0.3073 - val_acc: 0.9513\n",
      "Epoch 32/50\n",
      "1805/1805 [==============================] - 1s 680us/step - loss: 0.1110 - acc: 0.9994 - val_loss: 0.2886 - val_acc: 0.9535\n",
      "Epoch 33/50\n",
      "1805/1805 [==============================] - 1s 675us/step - loss: 0.0985 - acc: 0.9994 - val_loss: 0.2734 - val_acc: 0.9580\n",
      "Epoch 34/50\n",
      "1805/1805 [==============================] - 1s 684us/step - loss: 0.0875 - acc: 0.9994 - val_loss: 0.2620 - val_acc: 0.9535\n",
      "Epoch 35/50\n",
      "1805/1805 [==============================] - 1s 679us/step - loss: 0.0776 - acc: 0.9994 - val_loss: 0.2467 - val_acc: 0.9580\n",
      "Epoch 36/50\n",
      "1805/1805 [==============================] - 1s 678us/step - loss: 0.0686 - acc: 0.9994 - val_loss: 0.2355 - val_acc: 0.9580\n",
      "Epoch 37/50\n",
      "1805/1805 [==============================] - 1s 673us/step - loss: 0.0606 - acc: 1.0000 - val_loss: 0.2242 - val_acc: 0.9646\n",
      "Epoch 38/50\n",
      "1805/1805 [==============================] - 1s 670us/step - loss: 0.0536 - acc: 1.0000 - val_loss: 0.2138 - val_acc: 0.9624\n",
      "Epoch 39/50\n",
      "1805/1805 [==============================] - 1s 667us/step - loss: 0.0474 - acc: 1.0000 - val_loss: 0.2047 - val_acc: 0.9624\n",
      "Epoch 40/50\n",
      "1805/1805 [==============================] - 1s 680us/step - loss: 0.0417 - acc: 1.0000 - val_loss: 0.1966 - val_acc: 0.9624\n",
      "Epoch 41/50\n",
      "1805/1805 [==============================] - 1s 684us/step - loss: 0.0368 - acc: 1.0000 - val_loss: 0.1878 - val_acc: 0.9668\n",
      "Epoch 42/50\n",
      "1805/1805 [==============================] - 1s 708us/step - loss: 0.0324 - acc: 1.0000 - val_loss: 0.1792 - val_acc: 0.9690\n",
      "Epoch 43/50\n",
      "1805/1805 [==============================] - 1s 680us/step - loss: 0.0285 - acc: 1.0000 - val_loss: 0.1721 - val_acc: 0.9690\n",
      "Epoch 44/50\n",
      "1805/1805 [==============================] - 1s 692us/step - loss: 0.0251 - acc: 1.0000 - val_loss: 0.1675 - val_acc: 0.9690\n",
      "Epoch 45/50\n",
      "1805/1805 [==============================] - 1s 667us/step - loss: 0.0220 - acc: 1.0000 - val_loss: 0.1613 - val_acc: 0.9690\n",
      "Epoch 46/50\n",
      "1805/1805 [==============================] - 1s 677us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.1543 - val_acc: 0.9690\n",
      "Epoch 47/50\n",
      "1805/1805 [==============================] - 1s 669us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.1522 - val_acc: 0.9668\n",
      "Epoch 48/50\n",
      "1805/1805 [==============================] - 1s 683us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.1463 - val_acc: 0.9690\n",
      "Epoch 49/50\n",
      "1805/1805 [==============================] - 1s 675us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.1423 - val_acc: 0.9690\n",
      "Epoch 50/50\n",
      "1805/1805 [==============================] - 1s 695us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.1379 - val_acc: 0.9690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24268951a20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,dummy_y,batch_size=512,epochs=50,verbose=1,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict_classes(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8988015978695073\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
